# Vesuvius Faz 1: 3D Surface Detection

## ğŸ“‹ Proje AÃ§Ä±klamasÄ±

**Faz 1: Vesuvius 3D CT volume iÃ§in temel 3D U-Net ile binary surface segmentation.**

Bu proje, Vesuvius Challenge benzeri 3D CT verilerinde papirÃ¼s/kaÄŸÄ±t yÃ¼zeyini tespit etmek iÃ§in geliÅŸtirilmiÅŸ bir deep learning pipeline'Ä±dÄ±r. Faz 1'de sadece binary segmentation yapÄ±yoruz - CT volumÃ¼nde yÃ¼zey olan voxelleri (1) ve arka planÄ± (0) ayÄ±rÄ±yoruz.

### ğŸ¯ Hedefler
- 3D CT volumlerinden yÃ¼zey segmentasyonu
- ModÃ¼ler ve geniÅŸletilebilir kod yapÄ±sÄ±
- Hem lokal hem de Kaggle ortamÄ±nda Ã§alÄ±ÅŸabilme
- Ä°leride teacher-student, affinity, graph network gibi geliÅŸmiÅŸ tekniklere hazÄ±r altyapÄ±

## ğŸ—ï¸ Proje YapÄ±sÄ±

```
vesuvius_faz1/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ dataset.py          # 3D patch-based dataset loader
â”‚   â”œâ”€â”€ model_unet3d.py     # 3D U-Net model implementasyonu
â”‚   â”œâ”€â”€ losses.py           # BCE + Dice loss fonksiyonlarÄ±
â”‚   â”œâ”€â”€ utils.py            # Metrik, logging ve yardÄ±mcÄ± fonksiyonlar
â”‚   â””â”€â”€ train_faz1.py       # Ana training scripti
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ faz1_baseline.yaml  # Training konfigÃ¼rasyonu
â”œâ”€â”€ notebooks/              # Debug ve analiz iÃ§in (opsiyonel)
â”œâ”€â”€ requirements.txt        # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â””â”€â”€ README.md              # Bu dosya
```

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### Lokal Ã‡alÄ±ÅŸma

1. **Repository'yi klonla:**
```bash
git clone https://github.com/yourusername/vesuvius_faz1.git
cd vesuvius_faz1
```

2. **Sanal ortam oluÅŸtur (Ã¶nerilen):**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# veya
venv\Scripts\activate  # Windows
```

3. **BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kle:**
```bash
pip install -r requirements.txt
```

4. **Mini test verisi hazÄ±rla:**
```bash
# Ã–rnek veri yapÄ±sÄ± oluÅŸtur
mkdir -p data/vesuvius_mini/train/sample_1
mkdir -p data/vesuvius_mini/train/sample_2
mkdir -p data/vesuvius_mini/train/sample_3

# Test iÃ§in sahte veri oluÅŸturabilirsin (Python script ile)
python -c "
import numpy as np
import tifffile

# Sahte 3D volume oluÅŸtur
for i in range(1, 4):
    volume = np.random.randn(128, 256, 256).astype(np.float32)
    mask = (np.random.randn(128, 256, 256) > 0.5).astype(np.float32)
    
    tifffile.imwrite(f'data/vesuvius_mini/train/sample_{i}/ct.tif', volume)
    tifffile.imwrite(f'data/vesuvius_mini/train/sample_{i}/mask.tif', mask)
    
print('Test verisi oluÅŸturuldu!')
"
```

5. **Config dosyasÄ±nÄ± dÃ¼zenle:**
```bash
# configs/faz1_baseline.yaml dosyasÄ±nda:
# data_root: "./data/vesuvius_mini/train"  # Lokal path
```

6. **Training baÅŸlat:**
```bash
python src/train_faz1.py --config configs/faz1_baseline.yaml
```

### Kaggle Ãœzerinde Ã‡alÄ±ÅŸma

1. **GitHub'a yÃ¼kle:**
```bash
git add .
git commit -m "Initial commit"
git push origin main
```

2. **Kaggle Notebook'ta:**

Ä°lk hÃ¼cre - Repository'yi klonla ve setup yap:
```python
# Repository'yi klonla
!git clone https://github.com/yourusername/vesuvius_faz1.git
%cd vesuvius_faz1

# BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kle
!pip install -q -r requirements.txt
```

Ä°kinci hÃ¼cre - Config'i Kaggle iÃ§in gÃ¼ncelle:
```python
import yaml

# Config'i yÃ¼kle
with open('configs/faz1_baseline.yaml', 'r') as f:
    config = yaml.safe_load(f)

# Kaggle path'lerini ayarla
config['data_root'] = '/kaggle/input/vesuvius-dataset/train'
config['output_dir'] = '/kaggle/working/outputs'
config['device'] = 'cuda'  # Kaggle GPU

# GÃ¼ncellenmiÅŸ config'i kaydet
with open('configs/faz1_kaggle.yaml', 'w') as f:
    yaml.dump(config, f)

print("Config updated for Kaggle!")
```

ÃœÃ§Ã¼ncÃ¼ hÃ¼cre - Training baÅŸlat:
```python
# Training'i baÅŸlat
!python src/train_faz1.py --config configs/faz1_kaggle.yaml
```

## ğŸ“Š Veri FormatÄ±

Beklenen veri yapÄ±sÄ±:
```
data_root/
â”œâ”€â”€ sample_1/
â”‚   â”œâ”€â”€ ct.tif       # 3D CT volume [D, H, W]
â”‚   â””â”€â”€ mask.tif     # 3D binary mask [D, H, W]
â”œâ”€â”€ sample_2/
â”‚   â”œâ”€â”€ ct.tif
â”‚   â””â”€â”€ mask.tif
â””â”€â”€ ...
```

- **ct.tif**: 3D CT volume, float32 format
- **mask.tif**: Binary segmentation mask (0=background, 1=surface)

## âš™ï¸ KonfigÃ¼rasyon

Ana parametreler (`configs/faz1_baseline.yaml`):

### Data AyarlarÄ±
- `data_root`: Veri dizini
- `train_samples`: Training sample ID'leri
- `val_samples`: Validation sample ID'leri
- `patch_size`: 3D patch boyutu [D, H, W]
- `patch_stride`: Patch stride deÄŸerleri

### Model AyarlarÄ±
- `base_channels`: Ä°lk katman kanal sayÄ±sÄ± (16, 32, 64...)
- `num_levels`: U-Net derinliÄŸi (3, 4, 5...)
- `bilinear`: Upsampling metodu

### Training AyarlarÄ±
- `batch_size`: Batch boyutu (GPU belleÄŸine gÃ¶re)
- `epochs`: Epoch sayÄ±sÄ±
- `learning_rate`: Ã–ÄŸrenme hÄ±zÄ±
- `scheduler`: LR scheduler tipi ("reduce", "cosine", null)

### Loss AyarlarÄ±
- `bce_weight`: Binary Cross Entropy aÄŸÄ±rlÄ±ÄŸÄ±
- `dice_weight`: Dice loss aÄŸÄ±rlÄ±ÄŸÄ±

## ğŸ“ˆ Metrikler

Training sÄ±rasÄ±nda takip edilen metrikler:
- **Loss**: BCE + Dice combined loss
- **Dice Score**: Overlap metriÄŸi (0-1, 1=perfect)
- **IoU**: Intersection over Union
- **F1 Score**: Precision ve Recall dengesi

Metrikler `outputs/` klasÃ¶rÃ¼nde CSV formatÄ±nda kaydedilir.

## ğŸ’¾ Checkpoint Sistemi

Model checkpoint'leri ÅŸu ÅŸekilde kaydedilir:
- `checkpoint_epoch_XXX.pth`: Her epoch checkpoint'i
- `checkpoint_epoch_XXX_best.pth`: En iyi model
- `last_checkpoint.pth`: Son epoch

Checkpoint yÃ¼kleme:
```yaml
resume_checkpoint: "./outputs/checkpoints/last_checkpoint.pth"
```

## ğŸ”§ GeliÅŸmiÅŸ Ã–zellikler

### Custom Loss KombinasyonlarÄ±
```yaml
loss_config:
  bce:
    weight: 0.3
    pos_weight: 2.0  # Class imbalance iÃ§in
  dice:
    weight: 0.5
  focal:
    weight: 0.2
    alpha: 0.25
    gamma: 2.0
```

### Data Augmentation
- Random flips (X, Y, Z axes)
- Gaussian noise
- Config'ten kontrol edilebilir

### Memory Optimization
- `cache_volumes`: False yaparak RAM kullanÄ±mÄ±nÄ± azalt
- `batch_size`: GPU belleÄŸine gÃ¶re ayarla
- Gradient accumulation (gelecek sÃ¼rÃ¼m)

## ğŸ› Debug ve Test

Model test:
```python
python src/model_unet3d.py  # Model yapÄ±sÄ±nÄ± test et
```

Dataset test:
```python
python -c "
from src.dataset import VesuviusPatchDataset
import yaml

with open('configs/faz1_baseline.yaml') as f:
    config = yaml.safe_load(f)

dataset = VesuviusPatchDataset(
    config['data_root'],
    config['train_samples'],
    tuple(config['patch_size']),
    tuple(config['patch_stride'])
)

print(f'Dataset size: {len(dataset)}')
sample = dataset[0]
print(f'CT shape: {sample[\"ct\"].shape}')
print(f'Mask shape: {sample[\"mask\"].shape}')
"
```

## ğŸ“ Notlar

### GPU Bellek Optimizasyonu
- Batch size = 2 iÃ§in ~8GB GPU belleÄŸi gerekir
- Patch size kÃ¼Ã§Ã¼ltÃ¼lerek bellek kullanÄ±mÄ± azaltÄ±labilir
- Mixed precision training eklenebilir (gelecek sÃ¼rÃ¼m)

### Performans Ä°puÃ§larÄ±
- `cache_volumes=True`: HÄ±zlÄ± ama RAM kullanÄ±r
- `num_workers`: CPU sayÄ±sÄ±na gÃ¶re ayarla
- SSD disk kullanÄ±mÄ± Ã¶nerilir

### Gelecek GeliÅŸtirmeler (Faz 2+)
- [ ] Teacher-student learning
- [ ] Affinity field prediction
- [ ] Graph neural network integration
- [ ] Multi-scale training
- [ ] Advanced augmentations
- [ ] TensorBoard integration
- [ ] Mixed precision training
- [ ] Distributed training

## ğŸ¤ KatkÄ±da Bulunma

1. Fork yapÄ±n
2. Feature branch oluÅŸturun (`git checkout -b feature/amazing-feature`)
3. Commit yapÄ±n (`git commit -m 'Add amazing feature'`)
4. Push yapÄ±n (`git push origin feature/amazing-feature`)
5. Pull Request aÃ§Ä±n

## ğŸ“„ Lisans

Bu proje MIT lisansÄ± altÄ±ndadÄ±r. Detaylar iÃ§in LICENSE dosyasÄ±na bakÄ±n.

## ğŸ™ TeÅŸekkÃ¼rler

- Vesuvius Challenge organizatÃ¶rleri
- PyTorch ekibi
- Kaggle community

## ğŸ“§ Ä°letiÅŸim

Sorular iÃ§in issue aÃ§abilir veya [email@example.com] adresinden iletiÅŸime geÃ§ebilirsiniz.

---

**Not**: Bu Faz 1 implementasyonu temel bir baseline saÄŸlar. GerÃ§ek Vesuvius verisi Ã¼zerinde fine-tuning gerekebilir.